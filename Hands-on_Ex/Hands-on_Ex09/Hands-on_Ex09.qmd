---
title: "Hands-on exercise09"
author: "Yuheng Liang"
format: html
editor: visual
date: "Oct 22, 2024"
date-modified: "Oct 22, 2024"
execute: 
  eval: true
  echo: true
  freeze: true
---

# Hands-on exercise09

## 1.0 The data
### 1.1package
```{r}
pacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, tidyverse, gtsummary)
```
### 1.2 Geospatial Data Wrangling
importing geospatial data
```{r}
mpsz = st_read(dsn = "data/geospatial", layer= "MP14_SUBZONE_WEB_PL")
```
#### 1.2.1updating CRS information
The code chunk below updates the newly imported mpsz with the correct ESPG code
```{r}
mpsz_svy21 <- st_transform(mpsz,3414)
```

varify the newly transformed mpsz_svy21
```{r}
st_crs(mpsz_svy21)
```
the EPSG is 3414

reveal the extent
```{r}
st_bbox(mpsz_svy21)
```
### 1.3 Aspatial Data warning
#### 1.3.1Importing the aspatial data
```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```
display the data structure
```{r}
glimpse(condo_resale)
```
```{r}
head(condo_resale$LONGITUDE)
```
```{r}
head(condo_resale$LATITUDE)
```
display the summary statistics
```{r}
summary(condo_resale)
```
#### 1.3.2 Converting aspatial data frame into a sf object
convert the condo_resale tibble data frame into sf object
```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326)%>%
  st_transform(crs=3414)
```
 convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).
 
list the content
```{r}
head(condo_resale.sf)
```
## 2.0 Exploratory Data Analysis
### 2.1 EDA using statistical graphics
```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```
The figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.

Statistically, the skewed dsitribution can be normalised by using log transformation.
The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.

```{r}
condo_resale.sf <- condo_resale.sf%>%
  mutate(`LOG_SELLING_PRICE`=log(SELLING_PRICE))
```

plot it
```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```
### 2.2 Multiple Histogram Plots distribution of variables
draw a small multiple histograms

creat 12 histograms
```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + 
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, 
                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, 
          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,
          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  
          ncol = 3, nrow = 4)
```
### 2.3 Drawing Statistical Point Map
trun on the interactive mode of tmap
```{r}
tmap_mode("view")
```
create an interactive point symbol map
```{r}
tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))+
  tmap_options(check.and.fix = TRUE)
```
```{r}
tmap_mode("plot")
```
## 3.0 Hedonic Pricing Modellng in R
### 3.1 Simple Liner Regression Method
build a simple linear regression model
```{R}
condo.slr <- lm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

```{r}
summary(condo.slr)
```
y = -258121.1 + 14719x1
The R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.

Since p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.

The Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.

To visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot geometry 
```{r}
ggplot(data = condo_resale.sf,
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`))+
  geom_point()+
  geom_smooth(method = lm)
```
### 3.2 Multiple Linear Regression Method
#### 3.2.1 Visualising the relationships of the independent variables
plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame
```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```
Matrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.
From the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.

### 3.3 Building a hedonic pricing model using multiple linear regression method
```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + 
                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + 
                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + 
                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + 
                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, 
                data=condo_resale.sf)
summary(condo.mlr)
```

### 3.4 Preparing Publication Quality Table:olsrr mehod
with the reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.
```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + 
                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +
                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + 
                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + 
                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,
                 data=condo_resale.sf)
ols_regress(condo.mlr1)
```
### 3.5 Preparing Publication Quaity Table: gtsummary method
```{r}
tbl_regression(condo.mlr1,intercept = TRUE)
```
With gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note()

```{r}
tbl_regression(condo.mlr1,intercept = TRUE)%>%
  add_glance_source_note(label=list(sigma ~"\U03C3"),
                         include = c(r.squared,adj.r.squared,AIC,statistic,p.value,sigma))
```

#### 3.5.1 Checking for multicolinearity
the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity
```{r}
ols_vif_tol(condo.mlr1)
```

#### 3.5.2 Test for Non-Linearity
the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.
```{r}
ols_plot_resid_fit(condo.mlr1)
```
The figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.
#### 3.5.3 Test for Normality Assumption
use ols_plot_resid_hist() of olsrr package to perform normality assumption test.
```{r}
ols_plot_resid_hist(condo.mlr1)
```
The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.

formal statistical test methods
```{r}
ols_test_normality(condo.mlr1)
```
The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.

#### 3.5.4  Testing for Spatial Autocorrelation
In order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.
export the residual of the hedonic pricing model and save it as a data frame.
```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

join the newly created data frame with condo_resale.sf object.
```{r}
condo_resale.res.sf <- cbind(condo_resale.sf,condo.mlr1$residuals)%>%
  rename(`MLR_RES` = `condo.mlr1.residuals`)
```

convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.
```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```
use tmap package to display the distribution of the residuals on an interactive map.
```{r}
tmap_mode("view")
```

```{r}
tm_shape(mpsz_svy21)+
  tmap_options(check.and.fix = TRUE) +
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

```{r}
tmap_mode("plot")
```
To proof that our observation is indeed true, the Moran’s I test will be performed

compute the distance-based weight matrix by using dnearneigh() function of spdep
```{r}
nb <- dnearneigh(coordinates(condo_resale.sp),0,1500,longlat = FALSE)
summary(nb)
```

```{r}
nb_lw <- nb2listw(nb,style = 'W')
summary(nb_lw)
```
perform Moran’s I test for residual spatial autocorrelation
```{r}
lm.morantest(condo.mlr1,nb_lw)
```
The Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution.

